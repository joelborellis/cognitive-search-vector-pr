{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Search LangChain vector code sample\n",
    "This code demonstrates how to use Azure AI Search with OpenAI and the `langchain.vectorstores.azuresearch`` module.\n",
    "To run the code, install the following packages, including the `azure-search-documents==11.4.0b8` packaged, as noted in [LangChain docs](https://python.langchain.com/docs/integrations/vectorstores/azuresearch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-search-documents==11.4.0b8 \n",
    "! pip install openai\n",
    "! pip install python-dotenv\n",
    "! pip install langchain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries  \n",
    "import openai\n",
    "import os  \n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SemanticSettings,\n",
    "    SemanticConfiguration,\n",
    "    PrioritizedFields,\n",
    "    SemanticField\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Azure OpenAI settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure environment variables  \n",
    "load_dotenv()  \n",
    "openai.api_type: str = \"azure\"  \n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")  \n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  \n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")  \n",
    "model: str = \"text-embedding-ada-002\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure vector store settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_address: str = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")  \n",
    "vector_store_password: str = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\") \n",
    "index_name: str = \"shadow-documents-index\" "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings and vector store instances\n",
    "Read your data, generate OpenAI embeddings and export to a format to insert your search index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings: OpenAIEmbeddings = OpenAIEmbeddings(deployment=model, model=model, chunk_size=1, openai_api_key=openai.api_key, openai_api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), openai_api_type=\"azure\" )\n",
    "#index_name: str = \"langchain-vector-demo\"\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    "    semantic_configuration_name='my-semantic-config-langchain',\n",
    "        semantic_settings=SemanticSettings(\n",
    "            default_configuration='my-semantic-config-langchain',\n",
    "            configurations=[\n",
    "                SemanticConfiguration(\n",
    "                    name='my-semantic-config-langchain',\n",
    "                    prioritized_fields=PrioritizedFields(\n",
    "                        title_field=SemanticField(field_name='content'),\n",
    "                        prioritized_content_fields=[SemanticField(field_name='content')],\n",
    "                        prioritized_keywords_fields=[SemanticField(field_name='metadata')] # by default when data is loaded metadata contains the source directory frm where the document was loaded\n",
    "                    ))\n",
    "            ])\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store\n",
    "Load text files into the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
<<<<<<< HEAD
    "# open and read all the txt files and put them into the index\n",
=======
    "loader = TextLoader(\"../data/sample-data/state_of_the_union.txt\", encoding=\"utf-8\")\n",
>>>>>>> 692e2e38d5c29af8790b8280298a1e1f433730d9
    "\n",
    "directory = \"../data/txt/challenger_customer/\"\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        loader = TextLoader(os.path.join(directory, filename), encoding=\"utf-8\")\n",
    "        documents = loader.load()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "\n",
    "        vector_store.add_documents(documents=docs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emerging technologies . \n",
      " \n",
      "September 2002 –  June 2007  \n",
      "Director, Global Platforms and Distribution Alliances, Oracle  \n",
      "  \n",
      "• Recreated Oracle’s partnership with Dell resulting in the largest reseller by revenue.  Responsible for pipeline \n",
      "management, forecasting and closing opportunities through strategic part ners.  Worked closely with \n",
      "executive management within Oracle and their partners, directly negotiating contracts and identifying key \n",
      "partnership sales opportunities.  Led teams in technical integration efforts between Oracle and partners . \n",
      "  \n",
      "June 1998  – September 2002   \n",
      "Senior Software Engineer –  Applications Engineering, Blue Martini Software  \n",
      "  \n",
      "• Developed key product capabilities for Blue Martini’s retail applications .  Focused development on \n",
      "integration with other packaged application and legacy application architectures .  \n",
      "• Worked onsite with customers to maximize their software purchase and customize options for their business \n",
      "requirements . \n",
      "• Instrumental part of product launch team for first version of Blue Martini Platform at large retail client .  \n",
      "Fielded the first implementations of Blue Martini’s premier product suite to major customers . \n",
      "• Designed and implemented integrations between Blue Martini and existing legacy systems including \n",
      "developing re -useable platform for passing data to and from Blue Martini application . \n",
      "  \n",
      " \n",
      "Volunteer and Projects\n",
      "emerging technologies . \n",
      " \n",
      "September 2002 –  June 2007  \n",
      "Director, Global Platforms and Distribution Alliances, Oracle  \n",
      "  \n",
      "• Recreated Oracle’s partnership with Dell resulting in the largest reseller by revenue.  Responsible for pipeline \n",
      "management, forecasting and closing opportunities through strategic part ners.  Worked closely with \n",
      "executive management within Oracle and their partners, directly negotiating contracts and identifying key \n",
      "partnership sales opportunities.  Led teams in technical integration efforts between Oracle and partners . \n",
      "  \n",
      "June 1998  – September 2002   \n",
      "Senior Software Engineer –  Applications Engineering, Blue Martini Software  \n",
      "  \n",
      "• Developed key product capabilities for Blue Martini’s retail applications .  Focused development on \n",
      "integration with other packaged application and legacy application architectures .  \n",
      "• Worked onsite with customers to maximize their software purchase and customize options for their business \n",
      "requirements . \n",
      "• Instrumental part of product launch team for first version of Blue Martini Platform at large retail client .  \n",
      "Fielded the first implementations of Blue Martini’s premier product suite to major customers . \n",
      "• Designed and implemented integrations between Blue Martini and existing legacy systems including \n",
      "developing re -useable platform for passing data to and from Blue Martini application . \n",
      "  \n",
      " \n",
      "Volunteer and Projects\n",
      "June 200 7 – January 2016  \n",
      "Group Vice President, Worldwide Partner Enablement and Communications, Oracle  \n",
      "  \n",
      "• Led Oracle’s Worldwide Partner Enablement team.  Led the development  of partners capabilities to sell and \n",
      "implement Oracle products and solutions profitably a cross multiple channels and in mass scale, and for \n",
      "creating innovative framework and standards which allow for Oracle to define and measure partners skills \n",
      "and competencies across all product lines . \n",
      "• Served as Oracle Executive spokesperson to analysts and press for all partner related communications.   \n",
      "• Accountable for growth in partner capabilities supporting global consumption revenue goals, and for \n",
      "increasing partner loyalty to Oracle via communications and marketing programs and events .  \n",
      "• Led Oracle’s worldwide Technical Account Management team.  Established and developed sales enablement \n",
      "programs for global distributors and strategic partners.  Executed  pipeline management, forecasting and \n",
      "closing opportunities through global distributors and key partners . \n",
      "• Hired, trained,  and managed a team of technical account managers supporting partners sales . \n",
      "• Accountable for sales through enablement of and management of Oracle partners across established and \n",
      "emerging technologies . \n",
      " \n",
      "September 2002 –  June 2007  \n",
      "Director, Global Platforms and Distribution Alliances, Oracle\n"
     ]
    }
   ],
   "source": [
    "# Perform a similarity search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"did simon work at oracle\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "results = [doc.page_content for doc in docs]\n",
    "print(\"\\n\".join(results))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.S. and Canada.16 In addition to its impressive growth, it s users were highly engaged ; in the U.S., \n",
      "users  spent about 40 minutes per day on Facebook (see Exhibits 6a and 6b).17 \n",
      "This document is authorized for use only by Joel Borellis in Fa22 - NEW VENTURE STRATEGIES (06715) at UT Austin MSTC, 2022.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import AzureCognitiveSearchRetriever\n",
    "\n",
    "retriever = AzureCognitiveSearchRetriever(index_name=\"shadow-documents-index\", service_name=\"gtlopenaidemisearch\", api_key=vector_store_password, content_key=\"content\", top_k=1)    \n",
    "docs = retriever.get_relevant_documents(\"did joel work at Oracle\")\n",
    "\n",
    "results = [doc.page_content for doc in docs]\n",
    "print(\"\\n\".join(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a hybrid search\n",
    "docs = vector_store.hybrid_search(\n",
    "    query=\"What is challenger sales model\",\n",
    "    k=3, \n",
    "    search_type=\"hybrid\"\n",
    ")\n",
    "results = [doc.page_content for doc in docs]\n",
    "print(\"\\n\".join(results))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search with semantic reranking (powered by Bing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a hybrid search with semantic reranking  \n",
    "docs_and_scores = vector_store.semantic_hybrid_search_with_score(  \n",
    "    query=\"What is challenger sales model\",  \n",
    "    k=3,  \n",
    ")  \n",
    "  \n",
    "# Print the results  \n",
    "for doc, score in docs_and_scores:  \n",
    "    print(\"-\" * 80)  \n",
    "    answers = doc.metadata['answers']  \n",
    "    if answers:  \n",
    "        if answers.get('highlights'):  \n",
    "            print(f\"Semantic Answer: {answers['highlights']}\")  \n",
    "        else:  \n",
    "            print(f\"Semantic Answer: {answers['text']}\")  \n",
    "        print(f\"Semantic Answer Score: {score}\")  \n",
    "    print(\"Content:\", doc.page_content)  \n",
    "    captions = doc.metadata['captions']\n",
    "    print(f\"Score: {score}\") \n",
    "    if captions:  \n",
    "        if captions.get('highlights'):  \n",
    "            print(f\"Caption: {captions['highlights']}\")  \n",
    "        else:  \n",
    "            print(f\"Caption: {captions['text']}\")  \n",
    "    else:  \n",
    "        print(\"Caption not available\")  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
